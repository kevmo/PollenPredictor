{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521b2f84-2b3b-404b-942a-67145f9a5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4001369a-7ebe-479a-a474-79c711aabd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [........................................................................] 89753864 / 89753864"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./models/bees-wasps.h5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_url = \"https://github.com/alexeygrigorev/large-datasets/releases/download/wasps-bees/bees-wasps.h5\"\n",
    "keras_model_path = \"./models/bees-wasps.h5\"\n",
    "\n",
    "wget.download(keras_model_url, keras_model_path)\n",
    "\n",
    "keras_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a122e43-bd2b-47f7-8c9d-61e701394cc4",
   "metadata": {},
   "source": [
    "### Convert to tf-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "378fcc49-9b7f-44a4-bd0d-c7f0a417a781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 15:58:52.009995: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "keras_model = load_model(keras_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45dc130c-df06-49ea-bd14-8f5e9699c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x3/fy30qts964b_nfn299fxgj5r0000gn/T/tmpg5o78bt3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/x3/fy30qts964b_nfn299fxgj5r0000gn/T/tmpg5o78bt3/assets\n",
      "2023-11-28 16:00:20.900785: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-28 16:00:20.900809: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-28 16:00:20.902790: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/x3/fy30qts964b_nfn299fxgj5r0000gn/T/tmpg5o78bt3\n",
      "2023-11-28 16:00:20.904235: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-28 16:00:20.904256: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/x3/fy30qts964b_nfn299fxgj5r0000gn/T/tmpg5o78bt3\n",
      "2023-11-28 16:00:20.907724: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-28 16:00:20.908802: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-28 16:00:21.036332: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/x3/fy30qts964b_nfn299fxgj5r0000gn/T/tmpg5o78bt3\n",
      "2023-11-28 16:00:21.049942: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 147153 microseconds.\n",
      "2023-11-28 16:00:21.116137: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./models/bees-wasps.tflite'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_path = \"./models/bees-wasps.tflite\"\n",
    "\n",
    "with open(tflite_model_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "tflite_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36892393-91a0-4336-b838-e08d2a463223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 286272\n",
      "drwxr-xr-x  4 home  staff   128B Nov 28 16:00 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  5 home  staff   160B Nov 28 16:01 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--  1 home  staff    86M Nov 28 15:53 bees-wasps.h5\n",
      "-rw-r--r--  1 home  staff    43M Nov 28 16:00 bees-wasps.tflite\n"
     ]
    }
   ],
   "source": [
    "!ls -lah models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece75451-6429-4235-8d4e-2be431762ce9",
   "metadata": {},
   "source": [
    "### Examine input/output indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceeaf16c-0823-451b-a19c-7219121aded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 13,\n",
       "  'shape': array([1, 1], dtype=int32),\n",
       "  'shape_signature': array([-1,  1], dtype=int32),\n",
       "  'dtype': numpy.float32,\n",
       "  'quantization': (0.0, 0),\n",
       "  'quantization_parameters': {'scales': array([], dtype=float32),\n",
       "   'zero_points': array([], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Identify the output index for the TensorFlow Lite model\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get the output details\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Display the output details\n",
    "output_details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8880455-6a5e-4d6e-8725-7fa5faa6b5a3",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3d3bef-5023-422c-91bc-4d7f29f067d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size=(244, 244)):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08efa80d-a07a-4e3d-8e3e-d999f03865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_url = \"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\"\n",
    "image = download_image(image_url)\n",
    "prepared_image = prepare_image(image)\n",
    "\n",
    "# Display the prepared image\n",
    "prepared_image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4a4dbca-eb0d-4f76-9f72-054aa10e0183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value in the first pixel, R channel: 0.9450980392156862\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "def prepare_image(img, target_size=(150, 150)):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    img_array = np.array(img)  # Convert to Numpy array\n",
    "    img_array = img_array / 255.0  # Normalize to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Example usage:\n",
    "image_url = \"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\"\n",
    "image = download_image(image_url)\n",
    "prepared_image = prepare_image(image)\n",
    "\n",
    "# Display the value in the first pixel, R channel\n",
    "r_channel_value = prepared_image[0, 0, 0]  # Assuming HWC format (height, width, channels)\n",
    "print(f\"The value in the first pixel, R channel: {r_channel_value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66771a98-92c3-4971-b850-5acef15e2bdf",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e929bf1-d3d0-477f-8db7-766819f3dd05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have the model defined as described earlier in the conversation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/bees-wasps.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Replace with the actual path to your model weights\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Reshape the image to match the model's expected input shape\u001b[39;00m\n\u001b[1;32m      7\u001b[0m input_image \u001b[38;5;241m=\u001b[39m prepared_image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have the model defined as described earlier in the conversation\n",
    "\n",
    "# Load the model\n",
    "model.load_weights('./models/bees-wasps.tflite')  # Replace with the actual path to your model weights\n",
    "\n",
    "# Reshape the image to match the model's expected input shape\n",
    "input_image = prepared_image.reshape(1, 150, 150, 3)\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model.predict(input_image)\n",
    "\n",
    "# Display the model's output\n",
    "print(f\"The model's output for the given image: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0808f23b-28be-4c63-8c0b-d0aa48e497fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's output for the given image: [[0.6592137]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorFlow Lite model\n",
    "tflite_model_path = \"./models/bees-wasps.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Reshape the image to match the model's expected input shape\n",
    "input_image = prepared_image.reshape(1, 150, 150, 3).astype('float32')\n",
    "\n",
    "# Set the input tensor value\n",
    "interpreter.set_tensor(input_details[0]['index'], input_image)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get the output tensor value\n",
    "output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Display the model's output\n",
    "print(f\"The model's output for the given image: {output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e77daf-f97a-4c08-9636-e121bbd8bb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
